{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69c4ba1-85f3-4a02-ae37-c64347a01803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all relevant libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    " \n",
    "## This statement allows the visuals to render within your Jupyter Notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395e8bf-b530-4720-8d0f-26811e927d6e",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "We can now load the dataset into pandas using the read_csv() function. This converts the CSV file into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4030b0-aa7f-4bd7-8e9c-c1b7f4d202d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the csv file and convert to a Pandas dataframe\n",
    "cars_df=pd.read_csv(\"Data/data_saudi_used_cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f24681a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(cars_df, title=\"Profiling Report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5ed983-0f72-43eb-8168-6fafd48c562e",
   "metadata": {},
   "source": [
    "### Viewing the dataframe\n",
    "We can get a quick sense of the size of our dataset by using the shape method. This returns a tuple with the number of rows and columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f28a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5624, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b5bc4-db37-4432-b666-0714afd0c4ca",
   "metadata": {},
   "source": [
    "## 1. Data Profiling:\n",
    "Data profiling is a comprehensive process of examining the data available in an existing dataset and collecting statistics and information about that data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "672f2081-5a2c-4908-8cbd-29519fb3cac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Make</th>\n",
       "      <th>Gear_Type</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Options</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine_Size</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Negotiable</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corolla</td>\n",
       "      <td>Abha</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.4</td>\n",
       "      <td>421000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yukon</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>GMC</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Full</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>False</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Range Rover</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Land Rover</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Gulf Arabic</td>\n",
       "      <td>Full</td>\n",
       "      <td>2015</td>\n",
       "      <td>5.0</td>\n",
       "      <td>140000</td>\n",
       "      <td>False</td>\n",
       "      <td>260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optima</td>\n",
       "      <td>Hafar Al-Batin</td>\n",
       "      <td>Kia</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Semi Full</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.4</td>\n",
       "      <td>220000</td>\n",
       "      <td>False</td>\n",
       "      <td>42000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FJ</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Full</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Type          Region        Make  Gear_Type       Origin    Options  \\\n",
       "0      Corolla            Abha      Toyota     Manual        Saudi   Standard   \n",
       "1        Yukon          Riyadh         GMC  Automatic        Saudi       Full   \n",
       "2  Range Rover          Riyadh  Land Rover  Automatic  Gulf Arabic       Full   \n",
       "3       Optima  Hafar Al-Batin         Kia  Automatic        Saudi  Semi Full   \n",
       "4           FJ          Riyadh      Toyota  Automatic        Saudi       Full   \n",
       "\n",
       "   Year  Engine_Size  Mileage  Negotiable   Price  \n",
       "0  2013          1.4   421000        True       0  \n",
       "1  2014          8.0    80000       False  120000  \n",
       "2  2015          5.0   140000       False  260000  \n",
       "3  2015          2.4   220000       False   42000  \n",
       "4  2020          4.0    49000        True       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664ce68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5624 entries, 0 to 5623\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Type         5624 non-null   object \n",
      " 1   Region       5624 non-null   object \n",
      " 2   Make         5624 non-null   object \n",
      " 3   Gear_Type    5624 non-null   object \n",
      " 4   Origin       5624 non-null   object \n",
      " 5   Options      5624 non-null   object \n",
      " 6   Year         5624 non-null   int64  \n",
      " 7   Engine_Size  5624 non-null   float64\n",
      " 8   Mileage      5624 non-null   int64  \n",
      " 9   Negotiable   5624 non-null   bool   \n",
      " 10  Price        5624 non-null   int64  \n",
      "dtypes: bool(1), float64(1), int64(3), object(6)\n",
      "memory usage: 445.0+ KB\n"
     ]
    }
   ],
   "source": [
    "cars_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e6ed9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>5624.0</td>\n",
       "      <td>2014.101885</td>\n",
       "      <td>5.791606</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engine_Size</th>\n",
       "      <td>5624.0</td>\n",
       "      <td>3.295430</td>\n",
       "      <td>1.515108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mileage</th>\n",
       "      <td>5624.0</td>\n",
       "      <td>150923.375000</td>\n",
       "      <td>382835.963005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>196000.0</td>\n",
       "      <td>20000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>5624.0</td>\n",
       "      <td>53074.058144</td>\n",
       "      <td>70155.340614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36500.0</td>\n",
       "      <td>72932.5</td>\n",
       "      <td>850000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count           mean            std     min      25%       50%  \\\n",
       "Year         5624.0    2014.101885       5.791606  1963.0   2012.0    2016.0   \n",
       "Engine_Size  5624.0       3.295430       1.515108     1.0      2.0       3.0   \n",
       "Mileage      5624.0  150923.375000  382835.963005   100.0  38000.0  103000.0   \n",
       "Price        5624.0   53074.058144   70155.340614     0.0      0.0   36500.0   \n",
       "\n",
       "                  75%         max  \n",
       "Year           2018.0      2022.0  \n",
       "Engine_Size       4.5         9.0  \n",
       "Mileage      196000.0  20000000.0  \n",
       "Price         72932.5    850000.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd24ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9bfdbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a72d5d73474638a04d77d95f3b9f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915950656a6f4f2bbd67b80fffe75fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a9e9811d1848a790b563cc054f5ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc4e18a10244b43b0c296abdc329673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(cars_df, title=\"YData Profiling Report\", explorative=True)\n",
    "profile.to_file(\"ydata_profiling_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834929aa-fd6a-4ec5-84d4-77c4b3c1a506",
   "metadata": {},
   "source": [
    "The process of profiling differs slightly for categorical and numerical variables due to their inherent differences.\n",
    "\n",
    "**The two main types of data are:**\n",
    "- Quantitative (numerical) data\n",
    "- Qualitative (categorical) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9954f5-6fbc-45b4-ad86-3e21b6e0ca2d",
   "metadata": {},
   "source": [
    "### Data Quality Checks\n",
    "Data quality checks involve the process of ensuring that the data is accurate, complete, consistent, relevant, and reliable. \n",
    "\n",
    "\n",
    "**Here are typical steps involved in checking data quality:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818c876-173d-4e56-9e7d-b4334d2def25",
   "metadata": {},
   "source": [
    "#### 1. Reliability:\n",
    "Evaluate the data's source and collection process to determine its trustworthiness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9034ae7b-dc1d-4cba-8f9e-bb499d021cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ce0cc59-8c92-4acc-8d07-c40764e1a86b",
   "metadata": {},
   "source": [
    "#### 2. Timeliness: \n",
    "Ensure the data is up-to-date and reflective of the current situation or the period of interest for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78ae35-7226-4cb6-b8b2-a46c2ed17cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fab0fe2-6624-4615-b9d8-3c3669056bf8",
   "metadata": {},
   "source": [
    "#### 3. Consistency: \n",
    "\n",
    "Confirm that the data is consistent within the dataset and across multiple data sources. For example, the same data point should not have different values in different places.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fecc573-959f-4800-8ddd-a67985c68b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to check consistency it is one data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3d183-bba0-4b12-b963-487daab1e876",
   "metadata": {},
   "source": [
    "#### 4. Relevance: \n",
    "Assess whether the data is appropriate and applicable for the intended analysis. Data that is not relevant can skew results and lead to incorrect conclusions.\n",
    "\n",
    "**Key considerations for relevance include:**\n",
    "\n",
    "> 1. Sample Appropriateness: Confirm that your data sample aligns with your analysis objectives. For instance, utilizing data from the Northern region will not yield accurate insights for the Western region of the Kingdom.\n",
    ">\n",
    "> 2. Variable Selection: Any column will not be relevant for our analysis, we can get rid of these using the drop() method. We will set the “axis” argument to 1 since we’re dealing with columns, and set the “inplace” argument to True to make the change permanent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50a934b7-a0cd-443f-8a27-f10e9a6e8647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Region</th>\n",
       "      <th>Make</th>\n",
       "      <th>Gear_Type</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Options</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine_Size</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Negotiable</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Rio</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Kia</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.4</td>\n",
       "      <td>270000</td>\n",
       "      <td>False</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>Sonata</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.4</td>\n",
       "      <td>100</td>\n",
       "      <td>False</td>\n",
       "      <td>72910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>Tucson</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155000</td>\n",
       "      <td>False</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>Camry</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Saudi</td>\n",
       "      <td>Full</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.5</td>\n",
       "      <td>185000</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type  Region     Make  Gear_Type Origin   Options  Year  Engine_Size  \\\n",
       "953      Rio  Riyadh      Kia  Automatic  Saudi  Standard  2016          1.4   \n",
       "4646  Sonata  Jeddah  Hyundai  Automatic  Saudi  Standard  2020          2.4   \n",
       "4933  Tucson  Dammam  Hyundai  Automatic  Saudi  Standard  2016          2.0   \n",
       "5267   Camry  Riyadh   Toyota  Automatic  Saudi      Full  2013          2.5   \n",
       "\n",
       "      Mileage  Negotiable  Price  \n",
       "953    270000       False  25000  \n",
       "4646      100       False  72910  \n",
       "4933   155000       False  45000  \n",
       "5267   185000        True      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df[cars_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e3a2a-bbb7-4d06-8220-c93277b70146",
   "metadata": {},
   "source": [
    "#### 5. Uniqueness: \n",
    "Check for and remove duplicate records to prevent skewed analysis results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a509a7aa-58f4-4d39-8eb8-e8298a21f2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df= cars_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04c62559-3b48-48cf-a4e9-857e2e0ff416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to delete duplicates columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7724ac2-4ea2-4cf4-a9e0-e64368f87b92",
   "metadata": {},
   "source": [
    "#### 6. Completeness: \n",
    "Ensure that no critical data is missing. This might mean checking for null values or required fields that are empty.\n",
    "\n",
    "We will start by checking the dataset for missing or null values. For this, we can use the isna() method which returns a dataframe of boolean values indicating if a field is null or not. To group all missing values by column, we can include the sum() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a4de54-a344-4b94-9908-9528c15c13f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type           0\n",
       "Region         0\n",
       "Make           0\n",
       "Gear_Type      0\n",
       "Origin         0\n",
       "Options        0\n",
       "Year           0\n",
       "Engine_Size    0\n",
       "Mileage        0\n",
       "Negotiable     0\n",
       "Price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display number missing values per column\n",
    "cars_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e6d349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Land Cruiser    269\n",
       "Camry           234\n",
       "Hilux           207\n",
       "Accent          174\n",
       "Yukon           162\n",
       "               ... \n",
       "Nativa            1\n",
       "360               1\n",
       "GC7               1\n",
       "CT5               1\n",
       "S8                1\n",
       "Name: count, Length: 347, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abec31c4-0904-4b73-8cee-b7bc14ab1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to clean them "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40de63c-5a1d-49ed-a87e-c5229ee08bbe",
   "metadata": {},
   "source": [
    "#### 7. Check Accuracy:\n",
    "\n",
    "Verify that the data is correct and precise. This could involve comparing data samples with known sources or using validation rules.\n",
    "\n",
    "**The process includes:**\n",
    "1. Validating the appropriateness of data types for the dataset.\n",
    "2. Identifying outliers  using established validation  rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68be5334-ae10-4abd-8097-3259fe5e72c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type            object\n",
       "Region          object\n",
       "Make            object\n",
       "Gear_Type       object\n",
       "Origin          object\n",
       "Options         object\n",
       "Year             int64\n",
       "Engine_Size    float64\n",
       "Mileage          int64\n",
       "Negotiable        bool\n",
       "Price            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check columns types \n",
    "cars_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "priceQ1= cars_df['Price'].quantile(0.25)\n",
    "priceQ1= cars_df['Price'].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ee790ba-dcc0-45f1-b6f8-0133e913e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to clean them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69b303a-5459-45f9-a28e-fcee45c21c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca9d42-add6-45db-92cf-1f6dae5f277b",
   "metadata": {},
   "source": [
    "**What is an Outlier?** \n",
    "Outlier is an row/observation that appears far away and diverges from an overall pattern in a sample.\n",
    "\n",
    "**What are the types of Outliers?**\n",
    "1. Univariate: These outliers can be found when we look at distribution of a single variable\n",
    "2. Multivariate: are outliers in an n-dimensional space. In order to find them, you have to look at distributions in multi-dimensions. example (hight=100, weight=100) for a person\n",
    "\n",
    "**What causes Outliers?**\n",
    "Whenever we come across outliers, the ideal way to tackle them is to find out the reason of having these outliers. The method to deal with them would then depend on the reason of their occurrence.\n",
    "\n",
    "Let’s understand various types of outliers:\n",
    "\n",
    "1. Data Entry Errors:- Human errors such as errors caused during data collection, recording, or entry can cause outliers in data.\n",
    "2. Measurement Error: It is the most common source of outliers. This is caused when the measurement instrument used turns out to be faulty.\n",
    "3. Data Processing Error: Whenever we perform data mining, we extract data from multiple sources. It is possible that some manipulation or extraction errors may lead to outliers in the dataset.\n",
    "4. Sampling error: For instance, we have to measure the height of athletes. By mistake, we include a few basketball players in the sample. This inclusion is likely to cause outliers in the dataset.\n",
    "5. Natural Outlier: When an outlier is not artificial (due to error), it is a natural outlier. For instance: In my last assignment with one of the renowned insurance company, I noticed that the performance of top 50 financial advisors was far higher than rest of the population. Surprisingly, it was not due to any error. Hence, whenever we perform any data mining activity with advisors, we used to treat this segment separately.\n",
    "\n",
    "\n",
    "**What is the impact of Outliers on a dataset?**\n",
    "\n",
    "\n",
    "![image.png](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Outlier_31.png)\n",
    "\n",
    "\n",
    "\n",
    "**How to detect Outliers?**\n",
    "\n",
    "1. Most commonly used method to detect outliers is visualization (Univariate Graphical Analysis).\n",
    "\n",
    "We use 3 common visualization methods:\n",
    ">- Box-plot: A box plot is a method for graphically depicting groups of numerical data through their quartiles. The box extends from the Q1 to Q3 quartile values of the data, with a line at the median (Q2). The whiskers extend from the edges of the box to show the range of the data. Outlier points are those past the end of the whiskers. Box plots show robust measures of location and spread as well as providing information about symmetry and outliers.\n",
    ">\n",
    ">  \n",
    ">![image.png](https://miro.medium.com/v2/resize:fit:698/format:webp/1*VK5iHA2AB28HSZwWwUbNYg.png)\n",
    ">\n",
    ">\n",
    ">- Histogram\n",
    ">- Scatter Plot: A scatter plot is a mathematical diagram using Cartesian coordinates to display values for two variables for a set of data. The data are displayed as a collection of points, each having the value of one variable determining the position on the horizontal axis and the value of the other variable determining the position on the vertical axis. The points that are far from the population can be termed as an outlier.\n",
    ">\n",
    ">  \n",
    ">![image.png](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*Ov6aH-8yIwNoUxtMFwgx4g.png)\n",
    ">\n",
    ">\n",
    "\n",
    "2. Using statistical method (Univariate Non-Graphical analysis):\n",
    ">- Any value, which is beyond the range of -1.5 x IQR to 1.5 x IQR\n",
    " \n",
    "![image.png](https://www.whatissixsigma.net/wp-content/uploads/2015/07/Box-Plot-Diagram-to-identify-Outliers-figure-1.png)\n",
    "\n",
    ">- Use capping methods. Any value which out of range of 5th and 95th percentile can be considered as outlier\n",
    ">- Data points, three or more standard deviation away from mean are considered outlier: The Z-score is the signed number of standard deviations by which the value of an observation or data point is above the mean value of what is being observed or measured. While calculating the Z-score we re-scale and center the data and look for data points that are too far from zero. These data points which are way too far from zero will be treated as the outliers. In most of the cases, a threshold of 3 or -3 is used i.e if the Z-score value is greater than or less than 3 or -3 respectively, that data point will be identified as outliers.\n",
    "> - Outlier detection is merely a special case of the examination of data for influential data points and it also depends on the business understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74ea6194-cc01-45d8-be38-c4543eb1714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to univariate graphical analysis\n",
    "# go to lesson : data visualisation 1 - chart type section\n",
    "# then go to univariate graphical analysis\n",
    "# detect outliers using graphs varbaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ecf77b-480c-4f64-9485-95be805bc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to lesson: statistics 1 then statistics 3\n",
    "# then go to univariate Non graphical analysis\n",
    "# detect outliers using numerical statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee200da8-62b0-492d-b118-f4d665a1fb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e66d611-6958-4860-8522-9ada7fce40b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to delete ouliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e886ec7-388c-414b-ada7-803c2fb1f2cb",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning: \n",
    "\n",
    "Preliminary findings from data profiling can lead to cleaning the data by:\n",
    "- Handling missing values\n",
    "- Correcting errors.\n",
    "- Dealing with outliers.\n",
    "\n",
    "-------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21876b48-f5ec-4970-85a9-0520d45d8841",
   "metadata": {},
   "source": [
    "### Handling missing values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890d5a2-2a65-4090-9427-f89c0f011d3f",
   "metadata": {},
   "source": [
    "**Why my data has missing values?**\n",
    "They may occur at two stages:\n",
    "1. Data Extraction: It is possible that there are problems with extraction process. Errors at data extraction stage are typically easy to find and can be corrected easily as well.\n",
    "2. Data collection: These errors occur at time of data collection and are harder to correct.\n",
    "\n",
    "**Why do we need to handle the missing data?**\n",
    "To avoid:\n",
    "- Bias the conclusions.\n",
    "- Leading the business to make wrong decisions.\n",
    "\n",
    "**Which are the methods to treat missing values ?**\n",
    "1. Deletion: we delete rows where any of the variable is missing. Simplicity is one of the major advantage of this method, but this method reduces the power of model because it reduces the sample size.\n",
    "\n",
    "2. Imputation: is a method to fill in the missing values with estimated ones. This imputation is one of the most frequently used methods.\n",
    "\n",
    "    2.1. Mean/ Mode/ Median Imputation: It consists of replacing the missing data for a given attribute by the mean or median (quantitative attribute) or mode (qualitative attribute) of all known values of that variable.\n",
    "    > It can be of two types:\n",
    "    > - Generalized Imputation: In this case, we calculate the mean or median for all non missing values of that variable then replace missing value with mean or median.\n",
    "    > - Similar case Imputation: In this case, we calculate average for each group individually of non missing values then replace the missing value based on the group.\n",
    "\n",
    "    2.2. Constant Value\n",
    "   \n",
    "    2.3. Forward Filling\n",
    "   \n",
    "    2.4. Backward Filling\n",
    "\n",
    "6. Prediction Model:  Prediction model is one of the sophisticated method for handling missing data. Here, we create a predictive model to estimate values that will substitute the missing data.  In this case, we divide our data set into two sets: One set with no missing values for the variable and another one with missing values. First data set become training data set of the model while second data set with missing values is test data set and variable with missing values is treated as target variable. Next, we create a model to predict target variable based on other attributes of the training data set and populate missing values of test data set.\n",
    "\n",
    "> There are 2 drawbacks for this approach:\n",
    "> - The model estimated values are usually more well-behaved than the true values\n",
    "> - If there are no relationships with attributes in the data set and the attribute with missing values, then the model will not be precise for estimating missing values.\n",
    "\n",
    "9. KNN Imputation: In this method of imputation, the missing values of an attribute are imputed using the given number of attributes that are most similar to the attribute whose values are missing. The similarity of two attributes is determined using a distance function. It is also known to have certain advantage & disadvantages.\n",
    "\n",
    "   > **Advantages:**\n",
    "   > - k-nearest neighbour can predict both qualitative & quantitative attributes\n",
    "   > - Creation of predictive model for each attribute with missing data is not required\n",
    "   > - Attributes with multiple missing values can be easily treated\n",
    "   > - Correlation structure of the data is taken into consideration\n",
    "\n",
    "   > **Disadvantage:**\n",
    "   > - KNN algorithm is very time-consuming in analyzing large database. It searches through all the dataset looking for the most similar instances.\n",
    "   > - Choice of k-value is very critical. Higher value of k would include attributes which are significantly different from what we need whereas lower value of k implies missing out of significant attributes.\n",
    "\n",
    "--------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e741fb-71c1-46ad-a526-d8f0b1564dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "01287962-8077-4c01-8d1d-5f8aed6cb37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to 6th dimention --> Completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cee10f-0af8-44e5-b595-8e965294daad",
   "metadata": {},
   "source": [
    "### Correcting errors\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06273b88-a169-42e8-81f5-5d71cb3f9c21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d95da5-a3ba-473a-8243-aa177cadae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to 7th dimension Accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc7dbb-6867-44cf-8f99-1b969a80be40",
   "metadata": {},
   "source": [
    "### Dealing with outliers:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88347887-4bdf-48af-9486-cb8fe80c97af",
   "metadata": {},
   "source": [
    "**How to remove Outliers?**\n",
    "Most of the ways to deal with outliers are similar to the methods of missing values like deleting rows, transforming them, binning them, treat them as a separate group, imputing values and other statistical methods. Here, we will discuss the common techniques used to deal with outliers:\n",
    "\n",
    "1. Deleting rows: We delete outlier values if it is due to data entry error, data processing error or outlier rows are very small in numbers. We can also use trimming at both ends to remove outliers.\n",
    "\n",
    "2. Imputing: Like imputation of missing values, we can also impute outliers. We can use mean, median, mode imputation methods. Before imputing values, we should analyse if it is natural outlier or artificial. If it is artificial, we can go with imputing values. We can also use statistical model to predict values of outlier rows and after that we can impute it with predicted values.\n",
    "\n",
    "3. Treat separately: If there are significant number of outliers, we should treat them separately in the statistical model. One of the approach is to treat both groups as two different groups and build individual model for both groups and then combine the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25a585f0-2b9c-42fa-bf21-cacc6aa3be3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataFrame' has no attribute 'cars_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mcars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'cars_df'"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame.cars_df['Price']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98548b66-e309-4eb8-a5dc-65fe0abbf1e8",
   "metadata": {},
   "source": [
    "## 3. Univariate Analysis: \n",
    "\n",
    "This involves examining single variables to understand their characteristics (distribution, central tendency, dispersion, and shape).\n",
    "\n",
    "We calculate **numerical values** about the data that tells us about the distribution of the data. We also **draw graphs** showing visually how the data is distributed. **To answer the following questions about Features/characteristics of Data:**\n",
    "- Where is the center of the data? (location)\n",
    "- How much does the data vary? (scale)\n",
    "- What is the shape of the data? (shape)\n",
    "\n",
    "**The benefits of this analysis:**\n",
    "Statistics summary gives a high-level idea to identify whether the data has any outliers, data entry error, distribution of data such as the data is normally distributed or left/right skewed\n",
    "\n",
    "**In this step, we will explore variables one by one using following approaches:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6718111-7ac2-4fff-9851-654655b62e0b",
   "metadata": {},
   "source": [
    "### 1. Univariate Graphical Analysis:\n",
    "Method to perform uni-variate analysis will depend on whether the variable type is categorical or numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42e896df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Region', 'Make', 'Gear_Type', 'Origin', 'Options', 'Year',\n",
       "       'Engine_Size', 'Mileage', 'Negotiable', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8308f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price\n",
       "0         1796\n",
       "55000       90\n",
       "35000       89\n",
       "45000       87\n",
       "65000       86\n",
       "          ... \n",
       "2314         1\n",
       "181000       1\n",
       "182000       1\n",
       "66587        1\n",
       "154000       1\n",
       "Name: count, Length: 467, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_values=cars_df['Price'].value_counts()\n",
    "price_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd2dfeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     0,  55000,  35000,  45000,  65000,  30000,  50000,  75000,  40000,\n",
       "        25000,\n",
       "       ...\n",
       "       224500,   1086,   1595, 153500, 252000,   2314, 181000, 182000,  66587,\n",
       "       154000],\n",
       "      dtype='int64', name='Price', length=467)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_values.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "142b74ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1796,   90,   89,   87,   86,   84,   79,   70,   68,   65,   57,\n",
       "         56,   53,   50,   45,   45,   44,   44,   40,   39,   38,   38,\n",
       "         37,   34,   34,   33,   32,   31,   31,   31,   31,   30,   30,\n",
       "         30,   29,   28,   28,   28,   27,   27,   27,   26,   26,   25,\n",
       "         25,   24,   24,   24,   24,   24,   23,   23,   23,   23,   22,\n",
       "         21,   21,   21,   19,   19,   17,   17,   17,   17,   17,   17,\n",
       "         17,   16,   16,   16,   15,   15,   15,   14,   14,   14,   14,\n",
       "         14,   14,   13,   13,   13,   13,   13,   13,   13,   13,   12,\n",
       "         12,   12,   12,   11,   11,   11,   11,   11,   11,   11,   11,\n",
       "         11,   11,   11,   11,   10,   10,   10,   10,    9,    9,    9,\n",
       "          9,    9,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
       "          8,    7,    7,    7,    7,    7,    7,    7,    7,    7,    7,\n",
       "          7,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
       "          6,    6,    6,    6,    6,    6,    5,    5,    5,    5,    5,\n",
       "          5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
       "          5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
       "          4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
       "          4,    4,    4,    4,    4,    4,    4,    4,    3,    3,    3,\n",
       "          3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "          3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "          3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "          3,    3,    3,    3,    3,    3,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1,    1,    1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_values.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dffd32ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(cars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      2\u001b[0m          \u001b[38;5;66;03m#,facecolor = 'b', edgecolor = 'red',\u001b[39;00m\n\u001b[1;32m      3\u001b[0m          bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[1;32m      4\u001b[0m         ) \u001b[38;5;66;03m# bins = 6 means 6 bars\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d57c4b9-9bb3-494d-85dd-b8d39afda139",
   "metadata": {},
   "source": [
    "#### I. Categorical Variables:\n",
    "\n",
    "we’ll use frequency table to understand distribution of each category\n",
    "- Bar Chart (Ordinal) - Orderd\n",
    "- Pie Chart (Nominal) - non Orderd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ece4b7-5508-403a-8fb0-f519fc74272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.boxplot(marathodfn_df['Speed_Km/Hr'])\n",
    "plt.xlabel('Speed_Km/Hr')\n",
    "\n",
    "plt.title(f'Box plot of Speed_Km/Hr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2641f0d-80f2-493b-99b7-15476379a1e2",
   "metadata": {},
   "source": [
    "#### II. Numerical Variables:\n",
    "\n",
    "we need to understand the central tendency and spread of the variable (Descriptive Analysis) using:\n",
    "   - Box plot\n",
    "   - Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be16f08-a072-4a02-a3ee-6f9d57786fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d66677d3-44ad-414f-9b39-f9c1995ad043",
   "metadata": {},
   "source": [
    "### 2. Univariate Non-Graphical analysis: \n",
    "\n",
    "- Where is the center of the data? (location) --> **Measures of central tendency**\n",
    "- How much does the data vary? (scale) --> **Measure of variability**\n",
    "- What is the shape of the data? (shape) --> **Measures of variation combined with an average (measure of center) gives a good picture of the distribution of the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1414f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Region', 'Make', 'Gear_Type', 'Origin', 'Options', 'Year',\n",
       "       'Engine_Size', 'Mileage', 'Negotiable', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1058d84-e61e-4f5b-b66a-29931e77821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003.0 2020.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(393, 11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate (5th percentile) and (95th percentile)\n",
    "pq1 = cars_df['Year'].quantile(0.05)\n",
    "pq2 = cars_df['Year'].quantile(0.95)\n",
    "print(pq1, pq2)\n",
    "\n",
    "# Filter out outliers\n",
    "cars_df[(cars_df['Year'] < pq1) | (cars_df['Year'] > pq2)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a7f221d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'cars_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cars_df[cars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mcars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.05\u001b[39m))]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cars_df[cars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mcars_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.05\u001b[39m))]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'cars_df'"
     ]
    }
   ],
   "source": [
    "cars_df[cars_df['Year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09bb809-0edd-432b-bf23-abd0840b3e16",
   "metadata": {},
   "source": [
    "## 4. Bivariate/Multivariate Analysis:\n",
    "\n",
    "Here, you look at the relationships between two or more variables. This can involve looking for correlations, patterns, and trends that suggest a relationship or an association.\n",
    "\n",
    "We can perform bi-variate analysis for any combination of categorical and numerical variables. The combination can be:\n",
    "| bi-variate variables   | Plot type |\n",
    "| ------------- | ------------- |\n",
    "| Categorical & Categorical| Stacked Bar Chart |\n",
    "| Categorical & numerical  | scatter plot, histogram, box plot|\n",
    "| numerical  & numerical  | Scatter plot, line chart| \n",
    "\n",
    "\n",
    "Multivariate Analysis:\n",
    "- Heat map\n",
    "- Bar Chart\n",
    "- Scatter Chart\n",
    "- Line Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f2864-ce9e-4f15-99c8-052d053154a7",
   "metadata": {},
   "source": [
    "**Categorical & Categorical --> (Stacked Column Chart)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f9f2ac-8477-49ea-9c68-4fe44d4395b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "730e088f-fe13-40da-8fbb-686f5135fa4d",
   "metadata": {},
   "source": [
    "**Categorical & numerical --> (scatter plot, histogram, box plot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590e345-2051-4215-91ac-07d196b510ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20aed48d-b78e-46da-963f-e7f15e2f4dc7",
   "metadata": {},
   "source": [
    "**numerical & numerical --> (Scatter plot, line chart)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41023177-01cb-4f39-a750-12be71b13bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efb43b30-b1f0-48a4-a19c-195810cc8a0f",
   "metadata": {},
   "source": [
    "We could also use a correlation matrix to get more specific information about the relationship between these two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406f58f-b825-4a15-8f6e-c68ca66bd483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
